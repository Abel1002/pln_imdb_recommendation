# buscador perfecto solo por titulo

# main.py
import os
import pickle
import re
import difflib
from pathlib import Path
import time

import numpy as np
import pandas as pd
import faiss
from sentence_transformers import SentenceTransformer

# --------------------------------------------------------------------------- #
# configuraci√≥n
# --------------------------------------------------------------------------- #
DATA_FILE = "movies.csv"
MODEL_NAME = "sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2"
PKL_FILE = "model.pkl"  # motor serializado
METRICS_TXT = "metrics.txt"  # m√©tricas de la 1.¬™ generaci√≥n
TOP_K = 5  # n¬∫ de resultados a mostrar


# --------------------------------------------------------------------------- #
# utilidades
# --------------------------------------------------------------------------- #
def normaliza(t: str) -> str:
    """Baja a min√∫sculas y quita el a√±o entre par√©ntesis."""
    t = re.sub(r"\(\d{4}\)$", "", t).strip().lower()
    return t


def fuzzy_suggestion(query_norm, titles_norm) -> str:
    """Devuelve un t√≠tulo muy parecido en texto o la query original."""
    matches = difflib.get_close_matches(query_norm, titles_norm, n=1, cutoff=0.8)
    return matches[0] if matches else query_norm


# --------------------------------------------------------------------------- #
# 1¬™ vez: construir y guardar el motor
# --------------------------------------------------------------------------- #
def build_engine() -> None:
    print("‚öôÔ∏è  Construyendo motor de b√∫squeda‚Ä¶ (solo ocurrir√° una vez)")
    t0 = time.perf_counter()

    # 1) leer CSV
    df = pd.read_csv(DATA_FILE)
    titles_orig = df["title"].tolist()
    titles_norm = [normaliza(t) for t in titles_orig]

    # 2) modelo y embeddings
    model = SentenceTransformer(MODEL_NAME)
    emb = model.encode(
        titles_norm, convert_to_numpy=True, normalize_embeddings=True
    ).astype("float32")

    # 3) √≠ndice FAISS (Inner-Product exacto)
    index = faiss.IndexFlatIP(emb.shape[1])
    index.add(emb)

    # 4) serializar todo (embeddings ‚âà 5 MB, √≠ndice ‚âà igual)
    with open(PKL_FILE, "wb") as f:
        pickle.dump(
            dict(
                titles_orig=titles_orig,
                titles_norm=titles_norm,
                embeddings=emb,  # guardamos emb ‚Üí exactitud id√©ntica
                model_name=MODEL_NAME,
            ),
            f,
            protocol=pickle.HIGHEST_PROTOCOL,
        )

    # m√©tricas informativas
    dt = time.perf_counter() - t0
    Path(METRICS_TXT).write_text(
        f"Pel√≠culas: {len(titles_orig)}\n"
        f"Dim vector: {emb.shape[1]}\n"
        f"Tiempo total: {dt:.2f} s\n"
        f"Tama√±o model.pkl: {Path(PKL_FILE).stat().st_size/1e6:.1f} MB\n",
        encoding="utf-8",
    )
    print(f"‚úÖ Motor guardado en {PKL_FILE} ({dt:.1f}s).")


# --------------------------------------------------------------------------- #
# carga r√°pida
# --------------------------------------------------------------------------- #
def load_engine():
    data = pickle.load(open(PKL_FILE, "rb"))
    index = faiss.IndexFlatIP(data["embeddings"].shape[1])
    index.add(data["embeddings"])  # reconstruir √≠ndice en RAM
    model = SentenceTransformer(data["model_name"])  # se carga desde cach√© local
    return index, model, data["titles_orig"], data["titles_norm"]


# --------------------------------------------------------------------------- #
# b√∫squeda
# --------------------------------------------------------------------------- #
# --- B√∫squeda ---
def buscar(query, index, model, titles_orig, titles_clean, k=5):
    """
    Realiza una b√∫squeda sem√°ntica de pel√≠culas.
    Intenta corregir typos antes de la b√∫squeda sem√°ntica.
    """
    # Preprocesar la consulta
    q = normaliza(query)
    original_q_normalized = q  # Guardamos la consulta normalizada original

    # Sugerir correcci√≥n de typo si hay un t√≠tulo muy similar textualmente
    # Usamos los t√≠tulos normalizados para la comparaci√≥n textual.
    # Bajamos el cutoff para ser m√°s tolerantes con m√∫ltiples typos.
    # Nota: Esto puede aumentar sugerencias incorrectas para queries que NO son t√≠tulos.
    # Experimenta con este valor (ej: 0.6, 0.7, 0.75)
    suggestion = difflib.get_close_matches(
        q, titles_clean, n=1, cutoff=0.7
    )  # <-- CAMBIO AQU√ç

    if suggestion:
        corrected_query_normalized = suggestion[0]
        # Solo usamos la sugerencia si es diferente de la consulta normalizada original
        if corrected_query_normalized != original_q_normalized:
            # Encontrar el t√≠tulo original correspondiente a la sugerencia normalizada para mostrar al usuario
            try:
                original_suggested_title = titles_orig[
                    titles_clean.index(corrected_query_normalized)
                ]
                print(
                    f"(üí° ¬øQuiz√°s quisiste decir: '{original_suggested_title}'? Buscando '{corrected_query_normalized}')"
                )
            except ValueError:
                # Esto no deber√≠a pasar si la sugerencia viene de titles_clean, pero por seguridad
                print(
                    f"(üí° ¬øQuiz√°s quisiste decir: '{corrected_query_normalized}'? Buscando '{corrected_query_normalized}')"
                )

            q = corrected_query_normalized  # Usamos la sugerencia corregida para la b√∫squeda sem√°ntica
        # Else: Si la sugerencia es la misma que la consulta original (normalizada),
        # significa que la consulta ya es un t√≠tulo v√°lido o muy similar a uno.
        # En este caso, proceed with the original (normalized) query.
        else:
            print(
                "(‚úÖ La consulta parece correcta o es muy similar a un t√≠tulo existente. Realizando b√∫squeda sem√°ntica.)"
            )

    else:
        # No close textual match found (even with lower cutoff), proceed with semantic search on the original normalized query.
        print(
            "(üîé No se encontr√≥ una correcci√≥n textual cercana. Realizando b√∫squeda sem√°ntica con la consulta original.)"
        )

    # Obtener embedding de la consulta usando el modelo cargado
    # Aseguramos que la query_vec sea float32 para FAISS
    query_vec = model.encode(
        [q], convert_to_numpy=True, normalize_embeddings=True
    ).astype("float32")

    # Buscar los k m√°s similares en el √≠ndice FAISS
    distances, idx = index.search(query_vec, k)

    # Retornar t√≠tulos originales correspondientes a los √≠ndices encontrados
    # idx[0] contiene los √≠ndices para la primera (y √∫nica) query vector
    results = [titles_orig[i] for i in idx[0]]
    return results


# --- El resto del c√≥digo (normaliza, build_engine, load_engine, main) permanece igual ---
# Aseg√∫rate de reemplazar SOLO la funci√≥n 'buscar' en tu archivo main.py con esta versi√≥n.


# --------------------------------------------------------------------------- #
# programa interactivo
# --------------------------------------------------------------------------- #
def main():
    if not os.path.exists(PKL_FILE):
        build_engine()

    index, model, titles_orig, titles_norm = load_engine()
    print("üé¨ Motor listo. Escribe un t√≠tulo o ‚Äòapagar sistema‚Äô para salir.")

    while True:
        q = input("\n¬øPel√≠cula que buscas?: ").strip()
        if not q:
            continue
        if q.lower() == "apagar sistema":
            print("üëã Hasta pronto.")
            break

        for r in buscar(q, index, model, titles_orig, titles_norm):
            print(" ‚Ä¢", r)


if __name__ == "__main__":
    main()
